# ğŸš€ AIâ€‘Assisted Code Plagiarism Detection System

> ğŸ” *A similarityâ€‘based plagiarism detection engine for source code â€” **not** an AI authorship classifier.*

---

## âœ¨ Overview

This project implements an **endâ€‘toâ€‘end code plagiarism detection system** that focuses on **semantic, structural, and tokenâ€‘level similarity** rather than surfaceâ€‘level text matching.

Instead of asking *â€œWas this written by AI?â€*, the system answers the more realistic and industryâ€‘relevant question:

> **â€œHow similar is this code to existing code?â€**

This mirrors how real plagiarism engines work in academic and enterprise environments.

---

## ğŸ§  What This System Does

âœ… Accepts source code as input
âœ… Normalizes and parses code
âœ… Performs **ASTâ€‘based structural analysis**
âœ… Computes **tokenâ€‘level similarity**
âœ… Generates **semantic embeddings** using pretrained transformers
âœ… Performs fast similarity search using **FAISS**
âœ… Produces plagiarism scores and confidence metrics

---

## ğŸ—ï¸ System Architecture

```
User Code
   â†“
FastAPI Layer
   â†“
Code Normalizer
   â†“
AST Analyzer
   â†“
Token Similarity Engine
   â†“
Embedding Model (CodeBERT)
   â†“
FAISS Similarity Search
   â†“
Score Aggregator
   â†“
Results + Storage
```

Each layer is isolated to ensure **modularity**, **debuggability**, and **scalability**.

---

## ğŸ› ï¸ Tech Stack

* ğŸ **Python**
* âš¡ **FastAPI**
* ğŸ”¥ **PyTorch**
* ğŸ¤— **HuggingFace Transformers (CodeBERT)**
* ğŸŒ³ **Python AST**
* ğŸš€ **FAISS** (Vector Similarity Search)
* ğŸ—„ï¸ **SQLite** (for production usage)
* ğŸ“Š **Pandas & Matplotlib** (evaluation & visualization)

---

## ğŸ“‚ Project Structure

```
ai-code-plagiarism-detector/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/            # FastAPI routes
â”‚   â”œâ”€â”€ pipeline/       # Core analysis pipeline
â”‚   â”œâ”€â”€ storage/        # DB & FAISS logic
â”‚   â”œâ”€â”€ utils/          # Shared helpers (future use)
â”‚   â””â”€â”€ configs/        # Config placeholders
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ evaluate_dataset.py
â”‚   â”œâ”€â”€ analyze_results.py
â”‚   â””â”€â”€ plot_results.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Human & AI datasets
â”‚   â””â”€â”€ results/        # CSV outputs
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone <your-repo-url>
cd ai-code-plagiarism-detector
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate      # Linux / macOS
venv\Scripts\activate         # Windows
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ§ª Dataset & Evaluation

### ğŸ“Œ Dataset Used

* **Human Code:** Competitive programming solutions (LeetCodeâ€‘style)
* **AI Code:** Python programs generated using large language models

> âš ï¸ Evaluation is performed **offline** to avoid polluting production data.

---

## ğŸ“Š Evaluation Results & Visualizations

> ğŸ“ Place images inside `assets/` folder and update paths if needed.

### ğŸ“¦ Plagiarism Percentage Distribution

![Plagiarism Distribution](assets/plagiarism_boxplot.png)

**What this shows:**

* Human code exhibits higher similarity due to repeated algorithmic patterns
* AI code remains clustered near lower similarity values
* High plagiarism â‰  misconduct â€” it indicates reuse

---

### ğŸ¤– AI Probability Distribution

![AI Probability Distribution](assets/ai_probability_boxplot.png)

**What this shows:**

* AI probability reflects **similarity confidence**, not authorship
* Human solutions show higher variance due to standardized styles

---

### ğŸ“ˆ Plagiarism Percentage Histogram

![Plagiarism Histogram](assets/plagiarism_histogram.png)

**What this shows:**

* Human code forms a dense similarity cluster
* AI samples concentrate near zero similarity
* Behavior matches realâ€‘world plagiarism engines

---

## ğŸ“Œ Key Learnings

* Difference between **similarityâ€‘based systems** and **classifiers**
* Why dataset imbalance does **not** bias similarity engines
* Designing productionâ€‘ready ML pipelines
* Separating evaluation logic from live systems
* Debugging real ML infra issues (DB, FAISS, embeddings)

---

## ğŸ”® Future Work

âœ¨ Add explainability / reasoning for plagiarism scores
âœ¨ Improve APIâ€‘level result interpretation
âœ¨ Optimize performance for largeâ€‘scale datasets
âœ¨ Extend support to more programming languages

---

## âš ï¸ Disclaimer

This system measures **code similarity and reuse**, not authorship verification. High plagiarism scores indicate similarity patterns and do **not** imply unethical behavior.

---

ğŸš§ **Project Status:** Actively under development

